{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import sklearn.decomposition\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goldman Sachs API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Getting access token\n",
    "\n",
    "# auth_data = {\n",
    "#     'grant_type'    : 'client_credentials',\n",
    "# #     'client_id'     : '',\n",
    "# #     'client_secret' : '',\n",
    "#     'scope'         : 'read_product_data read_financial_data read_content'\n",
    "# }\n",
    "\n",
    "# # create Session instance\n",
    "# session = requests.Session()\n",
    "\n",
    "# # make a POST to retrieve access_token\n",
    "# auth_request = session.post('https://idfs.gs.com/as/token.oauth2', data = auth_data)\n",
    "# access_token_dict = json.loads(auth_request.text)\n",
    "# access_token = access_token_dict['access_token']\n",
    "\n",
    "# # update session headers\n",
    "# session.headers.update({'Authorization':'Bearer '+ access_token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Grabbing all gsids\n",
    "\n",
    "# request_url = 'https://api.marquee.gs.com/v1/data/USCANFPP_MINI/coverage?limit=100'\n",
    "# request = session.get(url=request_url)\n",
    "# data = json.loads(request.text)\n",
    "# df = pd.DataFrame(data['results'])\n",
    "# gsids = df.gsid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def getStock(gsid):\n",
    "#     payload = {\n",
    "#     \"startDate\": \"2013-03-04\",\n",
    "# #     \"endDate\": \"2016-07-13\",\n",
    "#         \"endDate\": \"2018-07-13\",\n",
    "#     \"where\": {\n",
    "#         \"gsid\": [gsid]\n",
    "#         }\n",
    "#     }\n",
    "#     request_url = 'https://api.marquee.gs.com/v1/data/USCANFPP_MINI/query'\n",
    "#     request = session.post(url=request_url, json = payload)\n",
    "#     results = json.loads(request.text)\n",
    "#     data = results['data']\n",
    "# #     print(data)\n",
    "#     return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('GSData.pickle','rb') as handle:\n",
    "    GSData=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GSData.keys()\n",
    "gsids,gsidDict,allStockData,IDNameTable=GSData['gsids'], GSData['gsidDict'], GSData['allStockData'], GSData['IDNameTable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findStock(gsid, allStockData):\n",
    "    for i in range(len(allStockData)):\n",
    "        if allStockData[i]['gsid'][0]==gsid:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findStock('26403', allStockData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab all stocks\n",
    "stockData=[];\n",
    "for i in range(0,99):\n",
    "    if i!=76:\n",
    "        stockData.append(allStockData[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subtractDates(date1, earliestDate):\n",
    "    return (datetime.strptime(date1, '%Y-%m-%d')-datetime.strptime(earliestDate, '%Y-%m-%d')).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get output \n",
    "\n",
    "Disney_df=allStockData[76]\n",
    "Disney_df.set_index('date',drop=True,inplace=True);\n",
    "Disney_df.drop(labels='updateTime', axis=1,inplace=True)\n",
    "Disney_df.drop(labels='gsid', axis=1,inplace=True)\n",
    "\n",
    "for index, row in Disney_df.iterrows():\n",
    "    Disney_df.loc[index,'SubtractDates']=subtractDates(index,'2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only select dates after 2015-1-1\n",
    "\n",
    "Disney_df=Disney_df[Disney_df['SubtractDates']>=0].copy(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if any null values\n",
    "Disney_df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab the scores for Disney\n",
    "yOutput=Disney_df.iloc[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yOutput=yOutput.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(652, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yOutput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5594723926380368"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(yOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,98):\n",
    "    stockData[i].set_index('date',drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,98):\n",
    "    stockData[i].drop(labels='updateTime', axis=1,inplace=True)\n",
    "    stockData[i].drop(labels='gsid', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting all Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allFrame=stockData[0];\n",
    "for jj in range(1,98):\n",
    "    allFrame=pd.concat([allFrame,stockData[jj]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,row in allFrame.iterrows():\n",
    "#     print(index)\n",
    "    allFrame.loc[index,'SubtractDates']=subtractDates(index,'2015-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only select dates after 2015-1-1\n",
    "\n",
    "allFrame=allFrame[allFrame['SubtractDates']>=0].copy(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allFrame.set_index('SubtractDates',drop=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(652, 393)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order probably not ideal\n",
    "allFrame.interpolate(method='spline', order=5, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Disney-time-tone.pkl','rb') as handle:\n",
    "    array_SA=pickle.load(handle)\n",
    "\n",
    "# Scale: 100 very good, -100 very bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 365)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_SA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SA_data={'SubtractDates': array_SA.transpose()[:,0], 'Sentiment': array_SA.transpose()[:,1]}\n",
    "df_SA=pd.DataFrame(SA_data).set_index('SubtractDates',drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allData=pd.concat([allFrame,df_SA],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_Data=allData.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allFrame.drop('SubtractDates',axis=1,inplace=True)\n",
    "filtered_Data.drop('SubtractDates',axis=1,inplace=True)\n",
    "allFrame=filtered_Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yOutput=Disney_df.iloc[:,0:4]\n",
    "yOutput=yOutput.as_matrix()\n",
    "yOutput.shape\n",
    "yOutput=yOutput[0:261,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yOutput.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Start PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(allFrame)\n",
    "# pca.fit(filtered_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(pca.components_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51429657 0.20320079 0.09599645 0.03807935 0.03068876 0.0266889\n",
      " 0.02105636 0.01121713 0.00935362 0.00806343]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9586413579456229\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData=pca.transform(allFrame)\n",
    "inputData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Not needed anymore\n",
    "\n",
    "inputData=inputData[:-2,:]\n",
    "inputData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yOutput=Disney_df.iloc[:,0:4]\n",
    "yOutput=yOutput.as_matrix()\n",
    "yOutput.shape\n",
    "yOutput=yOutput[1:260,:]\n",
    "yOutput.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feed into neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputData, yOutput, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testList=[];\n",
    "# for i in range(1,7):\n",
    "#     for j in range(1,7):\n",
    "\n",
    "#         model0 = Sequential()\n",
    "#         model0.add(Dense(10, input_shape=(10,), use_bias=True, kernel_initializer='random_uniform', activation='tanh', kernel_regularizer=regularizers.l2(0.2*j),activity_regularizer=regularizers.l1(1)))\n",
    "#         model0.add(Dropout(0.1*i))\n",
    "#         model0.add(Dense(4, use_bias=True, kernel_initializer='random_uniform', activation='tanh'))\n",
    "#         model0.output_shape\n",
    "#         model0.compile(loss='mean_absolute_error',\n",
    "#                       optimizer='adam')\n",
    "\n",
    "#         hist=model0.fit(inputData, yOutput, epochs=200, batch_size=16, validation_split=0.1, shuffle=True)\n",
    "#         testList.append(hist.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 103 samples, validate on 104 samples\n",
      "Epoch 1/300\n",
      "103/103 [==============================] - 0s 364us/step - loss: 6.7684 - val_loss: 5.9974\n",
      "Epoch 2/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 5.3573 - val_loss: 4.7903\n",
      "Epoch 3/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 4.2137 - val_loss: 3.7521\n",
      "Epoch 4/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 3.2019 - val_loss: 2.9079\n",
      "Epoch 5/300\n",
      "103/103 [==============================] - 0s 166us/step - loss: 2.4654 - val_loss: 2.2590\n",
      "Epoch 6/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 1.8081 - val_loss: 1.6708\n",
      "Epoch 7/300\n",
      "103/103 [==============================] - 0s 94us/step - loss: 1.3678 - val_loss: 1.3150\n",
      "Epoch 8/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 1.1187 - val_loss: 1.0430\n",
      "Epoch 9/300\n",
      "103/103 [==============================] - 0s 106us/step - loss: 0.9042 - val_loss: 0.8251\n",
      "Epoch 10/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.7563 - val_loss: 0.6884\n",
      "Epoch 11/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.6537 - val_loss: 0.6402\n",
      "Epoch 12/300\n",
      "103/103 [==============================] - 0s 102us/step - loss: 0.6151 - val_loss: 0.6011\n",
      "Epoch 13/300\n",
      "103/103 [==============================] - 0s 155us/step - loss: 0.5786 - val_loss: 0.5319\n",
      "Epoch 14/300\n",
      "103/103 [==============================] - 0s 186us/step - loss: 0.5403 - val_loss: 0.5090\n",
      "Epoch 15/300\n",
      "103/103 [==============================] - 0s 119us/step - loss: 0.5133 - val_loss: 0.5048\n",
      "Epoch 16/300\n",
      "103/103 [==============================] - 0s 116us/step - loss: 0.5096 - val_loss: 0.5115\n",
      "Epoch 17/300\n",
      "103/103 [==============================] - 0s 312us/step - loss: 0.5062 - val_loss: 0.4868\n",
      "Epoch 18/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.4835 - val_loss: 0.4933\n",
      "Epoch 19/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.4868 - val_loss: 0.4632\n",
      "Epoch 20/300\n",
      "103/103 [==============================] - 0s 117us/step - loss: 0.4688 - val_loss: 0.4683\n",
      "Epoch 21/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.4677 - val_loss: 0.4657\n",
      "Epoch 22/300\n",
      "103/103 [==============================] - 0s 116us/step - loss: 0.4541 - val_loss: 0.4481\n",
      "Epoch 23/300\n",
      "103/103 [==============================] - 0s 157us/step - loss: 0.4508 - val_loss: 0.4473\n",
      "Epoch 24/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.4506 - val_loss: 0.4438\n",
      "Epoch 25/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.4490 - val_loss: 0.4259\n",
      "Epoch 26/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.4298 - val_loss: 0.4165\n",
      "Epoch 27/300\n",
      "103/103 [==============================] - 0s 177us/step - loss: 0.4231 - val_loss: 0.4098\n",
      "Epoch 28/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.4074 - val_loss: 0.4041\n",
      "Epoch 29/300\n",
      "103/103 [==============================] - 0s 68us/step - loss: 0.4041 - val_loss: 0.4061\n",
      "Epoch 30/300\n",
      "103/103 [==============================] - 0s 224us/step - loss: 0.4124 - val_loss: 0.4002\n",
      "Epoch 31/300\n",
      "103/103 [==============================] - 0s 352us/step - loss: 0.4071 - val_loss: 0.4032\n",
      "Epoch 32/300\n",
      "103/103 [==============================] - 0s 171us/step - loss: 0.4111 - val_loss: 0.4126\n",
      "Epoch 33/300\n",
      "103/103 [==============================] - 0s 143us/step - loss: 0.4066 - val_loss: 0.3855\n",
      "Epoch 34/300\n",
      "103/103 [==============================] - 0s 117us/step - loss: 0.3933 - val_loss: 0.3981\n",
      "Epoch 35/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.3934 - val_loss: 0.3777\n",
      "Epoch 36/300\n",
      "103/103 [==============================] - 0s 204us/step - loss: 0.3739 - val_loss: 0.3733\n",
      "Epoch 37/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.3671 - val_loss: 0.3493\n",
      "Epoch 38/300\n",
      "103/103 [==============================] - 0s 156us/step - loss: 0.3459 - val_loss: 0.3445\n",
      "Epoch 39/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.3448 - val_loss: 0.3438\n",
      "Epoch 40/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.3348 - val_loss: 0.3330\n",
      "Epoch 41/300\n",
      "103/103 [==============================] - 0s 68us/step - loss: 0.3340 - val_loss: 0.3236\n",
      "Epoch 42/300\n",
      "103/103 [==============================] - 0s 128us/step - loss: 0.3287 - val_loss: 0.3479\n",
      "Epoch 43/300\n",
      "103/103 [==============================] - 0s 69us/step - loss: 0.3381 - val_loss: 0.3227\n",
      "Epoch 44/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.3178 - val_loss: 0.3171\n",
      "Epoch 45/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.3162 - val_loss: 0.3069\n",
      "Epoch 46/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.3011 - val_loss: 0.2889\n",
      "Epoch 47/300\n",
      "103/103 [==============================] - 0s 104us/step - loss: 0.2956 - val_loss: 0.2956\n",
      "Epoch 48/300\n",
      "103/103 [==============================] - 0s 103us/step - loss: 0.2952 - val_loss: 0.3090\n",
      "Epoch 49/300\n",
      "103/103 [==============================] - 0s 147us/step - loss: 0.3023 - val_loss: 0.2978\n",
      "Epoch 50/300\n",
      "103/103 [==============================] - 0s 117us/step - loss: 0.2904 - val_loss: 0.2794\n",
      "Epoch 51/300\n",
      "103/103 [==============================] - 0s 89us/step - loss: 0.2776 - val_loss: 0.2647\n",
      "Epoch 52/300\n",
      "103/103 [==============================] - 0s 87us/step - loss: 0.2825 - val_loss: 0.2826\n",
      "Epoch 53/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.2795 - val_loss: 0.2729\n",
      "Epoch 54/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.2823 - val_loss: 0.2903\n",
      "Epoch 55/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.2857 - val_loss: 0.2833\n",
      "Epoch 56/300\n",
      "103/103 [==============================] - 0s 175us/step - loss: 0.2795 - val_loss: 0.2627\n",
      "Epoch 57/300\n",
      "103/103 [==============================] - 0s 100us/step - loss: 0.2745 - val_loss: 0.2514\n",
      "Epoch 58/300\n",
      "103/103 [==============================] - 0s 224us/step - loss: 0.2540 - val_loss: 0.2637\n",
      "Epoch 59/300\n",
      "103/103 [==============================] - 0s 142us/step - loss: 0.2723 - val_loss: 0.2743\n",
      "Epoch 60/300\n",
      "103/103 [==============================] - 0s 133us/step - loss: 0.2770 - val_loss: 0.2674\n",
      "Epoch 61/300\n",
      "103/103 [==============================] - 0s 87us/step - loss: 0.2590 - val_loss: 0.2585\n",
      "Epoch 62/300\n",
      "103/103 [==============================] - 0s 114us/step - loss: 0.2546 - val_loss: 0.2540\n",
      "Epoch 63/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.2455 - val_loss: 0.2603\n",
      "Epoch 64/300\n",
      "103/103 [==============================] - 0s 86us/step - loss: 0.2487 - val_loss: 0.2399\n",
      "Epoch 65/300\n",
      "103/103 [==============================] - 0s 91us/step - loss: 0.2339 - val_loss: 0.2278\n",
      "Epoch 66/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.2225 - val_loss: 0.2272\n",
      "Epoch 67/300\n",
      "103/103 [==============================] - 0s 108us/step - loss: 0.2256 - val_loss: 0.2324\n",
      "Epoch 68/300\n",
      "103/103 [==============================] - 0s 96us/step - loss: 0.2267 - val_loss: 0.2326\n",
      "Epoch 69/300\n",
      "103/103 [==============================] - 0s 93us/step - loss: 0.2195 - val_loss: 0.2263\n",
      "Epoch 70/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.2150 - val_loss: 0.2114\n",
      "Epoch 71/300\n",
      "103/103 [==============================] - 0s 95us/step - loss: 0.2107 - val_loss: 0.2125\n",
      "Epoch 72/300\n",
      "103/103 [==============================] - 0s 83us/step - loss: 0.2090 - val_loss: 0.2284\n",
      "Epoch 73/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.2239 - val_loss: 0.2131\n",
      "Epoch 74/300\n",
      "103/103 [==============================] - 0s 233us/step - loss: 0.2126 - val_loss: 0.2364\n",
      "Epoch 75/300\n",
      "103/103 [==============================] - 0s 302us/step - loss: 0.2199 - val_loss: 0.2068\n",
      "Epoch 76/300\n",
      "103/103 [==============================] - 0s 156us/step - loss: 0.1981 - val_loss: 0.2162\n",
      "Epoch 77/300\n",
      "103/103 [==============================] - 0s 438us/step - loss: 0.2054 - val_loss: 0.2056\n",
      "Epoch 78/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.2050 - val_loss: 0.2204\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 146us/step - loss: 0.2130 - val_loss: 0.2057\n",
      "Epoch 80/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.2045 - val_loss: 0.2075\n",
      "Epoch 81/300\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.208 - 0s 171us/step - loss: 0.2030 - val_loss: 0.1940\n",
      "Epoch 82/300\n",
      "103/103 [==============================] - 0s 140us/step - loss: 0.1949 - val_loss: 0.2120\n",
      "Epoch 83/300\n",
      "103/103 [==============================] - 0s 94us/step - loss: 0.1932 - val_loss: 0.1865\n",
      "Epoch 84/300\n",
      "103/103 [==============================] - 0s 204us/step - loss: 0.1803 - val_loss: 0.2051\n",
      "Epoch 85/300\n",
      "103/103 [==============================] - 0s 123us/step - loss: 0.1996 - val_loss: 0.2065\n",
      "Epoch 86/300\n",
      "103/103 [==============================] - 0s 175us/step - loss: 0.1969 - val_loss: 0.2069\n",
      "Epoch 87/300\n",
      "103/103 [==============================] - 0s 458us/step - loss: 0.1966 - val_loss: 0.1948\n",
      "Epoch 88/300\n",
      "103/103 [==============================] - 0s 103us/step - loss: 0.1856 - val_loss: 0.1980\n",
      "Epoch 89/300\n",
      "103/103 [==============================] - 0s 120us/step - loss: 0.1864 - val_loss: 0.1739\n",
      "Epoch 90/300\n",
      "103/103 [==============================] - 0s 310us/step - loss: 0.1566 - val_loss: 0.1692\n",
      "Epoch 91/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1580 - val_loss: 0.1757\n",
      "Epoch 92/300\n",
      "103/103 [==============================] - 0s 98us/step - loss: 0.1794 - val_loss: 0.1680\n",
      "Epoch 93/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1623 - val_loss: 0.1745\n",
      "Epoch 94/300\n",
      "103/103 [==============================] - 0s 204us/step - loss: 0.1683 - val_loss: 0.1651\n",
      "Epoch 95/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.1611 - val_loss: 0.1583\n",
      "Epoch 96/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1570 - val_loss: 0.1565\n",
      "Epoch 97/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1493 - val_loss: 0.1547\n",
      "Epoch 98/300\n",
      "103/103 [==============================] - 0s 408us/step - loss: 0.1455 - val_loss: 0.1513\n",
      "Epoch 99/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1474 - val_loss: 0.1650\n",
      "Epoch 100/300\n",
      "103/103 [==============================] - 0s 90us/step - loss: 0.1590 - val_loss: 0.1540\n",
      "Epoch 101/300\n",
      "103/103 [==============================] - 0s 118us/step - loss: 0.1548 - val_loss: 0.1520\n",
      "Epoch 102/300\n",
      "103/103 [==============================] - 0s 165us/step - loss: 0.1516 - val_loss: 0.1452\n",
      "Epoch 103/300\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.143 - 0s 146us/step - loss: 0.1348 - val_loss: 0.1458\n",
      "Epoch 104/300\n",
      "103/103 [==============================] - 0s 93us/step - loss: 0.1440 - val_loss: 0.1554\n",
      "Epoch 105/300\n",
      "103/103 [==============================] - 0s 225us/step - loss: 0.1539 - val_loss: 0.1505\n",
      "Epoch 106/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.1450 - val_loss: 0.1503\n",
      "Epoch 107/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.1470 - val_loss: 0.1551\n",
      "Epoch 108/300\n",
      "103/103 [==============================] - 0s 133us/step - loss: 0.1456 - val_loss: 0.1535\n",
      "Epoch 109/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1461 - val_loss: 0.1498\n",
      "Epoch 110/300\n",
      "103/103 [==============================] - 0s 134us/step - loss: 0.1423 - val_loss: 0.1343\n",
      "Epoch 111/300\n",
      "103/103 [==============================] - 0s 145us/step - loss: 0.1323 - val_loss: 0.1265\n",
      "Epoch 112/300\n",
      "103/103 [==============================] - 0s 133us/step - loss: 0.1246 - val_loss: 0.1466\n",
      "Epoch 113/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.1327 - val_loss: 0.1497\n",
      "Epoch 114/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.1348 - val_loss: 0.1433\n",
      "Epoch 115/300\n",
      "103/103 [==============================] - 0s 102us/step - loss: 0.1347 - val_loss: 0.1413\n",
      "Epoch 116/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.1383 - val_loss: 0.1325\n",
      "Epoch 117/300\n",
      "103/103 [==============================] - 0s 91us/step - loss: 0.1322 - val_loss: 0.1310\n",
      "Epoch 118/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.1227 - val_loss: 0.1407\n",
      "Epoch 119/300\n",
      "103/103 [==============================] - 0s 102us/step - loss: 0.1316 - val_loss: 0.1284\n",
      "Epoch 120/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1193 - val_loss: 0.1231\n",
      "Epoch 121/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1184 - val_loss: 0.1450\n",
      "Epoch 122/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1365 - val_loss: 0.1696\n",
      "Epoch 123/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1473 - val_loss: 0.1503\n",
      "Epoch 124/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1323 - val_loss: 0.1526\n",
      "Epoch 125/300\n",
      "103/103 [==============================] - 0s 117us/step - loss: 0.1331 - val_loss: 0.1294\n",
      "Epoch 126/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1293 - val_loss: 0.1319\n",
      "Epoch 127/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1234 - val_loss: 0.1285\n",
      "Epoch 128/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.1188 - val_loss: 0.1358\n",
      "Epoch 129/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1245 - val_loss: 0.1411\n",
      "Epoch 130/300\n",
      "103/103 [==============================] - 0s 76us/step - loss: 0.1247 - val_loss: 0.1207\n",
      "Epoch 131/300\n",
      "103/103 [==============================] - 0s 117us/step - loss: 0.1141 - val_loss: 0.1182\n",
      "Epoch 132/300\n",
      "103/103 [==============================] - 0s 104us/step - loss: 0.1120 - val_loss: 0.1217\n",
      "Epoch 133/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1258 - val_loss: 0.1275\n",
      "Epoch 134/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1124 - val_loss: 0.1398\n",
      "Epoch 135/300\n",
      "103/103 [==============================] - 0s 109us/step - loss: 0.1201 - val_loss: 0.1387\n",
      "Epoch 136/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.1262 - val_loss: 0.1284\n",
      "Epoch 137/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.1151 - val_loss: 0.1393\n",
      "Epoch 138/300\n",
      "103/103 [==============================] - 0s 92us/step - loss: 0.1346 - val_loss: 0.1382\n",
      "Epoch 139/300\n",
      "103/103 [==============================] - 0s 86us/step - loss: 0.1330 - val_loss: 0.1322\n",
      "Epoch 140/300\n",
      "103/103 [==============================] - 0s 108us/step - loss: 0.1226 - val_loss: 0.1106\n",
      "Epoch 141/300\n",
      "103/103 [==============================] - 0s 87us/step - loss: 0.1049 - val_loss: 0.1140\n",
      "Epoch 142/300\n",
      "103/103 [==============================] - 0s 95us/step - loss: 0.1124 - val_loss: 0.1181\n",
      "Epoch 143/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.1166 - val_loss: 0.1191\n",
      "Epoch 144/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1069 - val_loss: 0.1283\n",
      "Epoch 145/300\n",
      "103/103 [==============================] - 0s 86us/step - loss: 0.1117 - val_loss: 0.1262\n",
      "Epoch 146/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1162 - val_loss: 0.1257\n",
      "Epoch 147/300\n",
      "103/103 [==============================] - 0s 115us/step - loss: 0.1111 - val_loss: 0.1282\n",
      "Epoch 148/300\n",
      "103/103 [==============================] - 0s 95us/step - loss: 0.1092 - val_loss: 0.1319\n",
      "Epoch 149/300\n",
      "103/103 [==============================] - 0s 96us/step - loss: 0.1138 - val_loss: 0.1173\n",
      "Epoch 150/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1137 - val_loss: 0.1119\n",
      "Epoch 151/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1074 - val_loss: 0.1300\n",
      "Epoch 152/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1078 - val_loss: 0.1220\n",
      "Epoch 153/300\n",
      "103/103 [==============================] - 0s 87us/step - loss: 0.1083 - val_loss: 0.1258\n",
      "Epoch 154/300\n",
      "103/103 [==============================] - 0s 128us/step - loss: 0.1155 - val_loss: 0.1513\n",
      "Epoch 155/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1365 - val_loss: 0.1337\n",
      "Epoch 156/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1255 - val_loss: 0.1318\n",
      "Epoch 157/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 87us/step - loss: 0.1224 - val_loss: 0.1186\n",
      "Epoch 158/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1068 - val_loss: 0.1092\n",
      "Epoch 159/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.0998 - val_loss: 0.1240\n",
      "Epoch 160/300\n",
      "103/103 [==============================] - 0s 96us/step - loss: 0.1105 - val_loss: 0.1079\n",
      "Epoch 161/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.1023 - val_loss: 0.1236\n",
      "Epoch 162/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1127 - val_loss: 0.1179\n",
      "Epoch 163/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.1043 - val_loss: 0.1161\n",
      "Epoch 164/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1110 - val_loss: 0.1213\n",
      "Epoch 165/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1103 - val_loss: 0.1175\n",
      "Epoch 166/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1071 - val_loss: 0.1088\n",
      "Epoch 167/300\n",
      "103/103 [==============================] - 0s 102us/step - loss: 0.1115 - val_loss: 0.1270\n",
      "Epoch 168/300\n",
      "103/103 [==============================] - 0s 68us/step - loss: 0.1148 - val_loss: 0.1286\n",
      "Epoch 169/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1099 - val_loss: 0.1149\n",
      "Epoch 170/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1108 - val_loss: 0.1080\n",
      "Epoch 171/300\n",
      "103/103 [==============================] - 0s 76us/step - loss: 0.0993 - val_loss: 0.1069\n",
      "Epoch 172/300\n",
      "103/103 [==============================] - 0s 87us/step - loss: 0.1025 - val_loss: 0.1160\n",
      "Epoch 173/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1020 - val_loss: 0.1239\n",
      "Epoch 174/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1091 - val_loss: 0.1195\n",
      "Epoch 175/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1071 - val_loss: 0.1208\n",
      "Epoch 176/300\n",
      "103/103 [==============================] - 0s 68us/step - loss: 0.1101 - val_loss: 0.1231\n",
      "Epoch 177/300\n",
      "103/103 [==============================] - 0s 157us/step - loss: 0.1115 - val_loss: 0.1159\n",
      "Epoch 178/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1144 - val_loss: 0.1296\n",
      "Epoch 179/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1221 - val_loss: 0.1395\n",
      "Epoch 180/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1315 - val_loss: 0.1468\n",
      "Epoch 181/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1298 - val_loss: 0.1434\n",
      "Epoch 182/300\n",
      "103/103 [==============================] - 0s 98us/step - loss: 0.1326 - val_loss: 0.1367\n",
      "Epoch 183/300\n",
      "103/103 [==============================] - 0s 117us/step - loss: 0.1197 - val_loss: 0.1264\n",
      "Epoch 184/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1175 - val_loss: 0.1246\n",
      "Epoch 185/300\n",
      "103/103 [==============================] - 0s 93us/step - loss: 0.1188 - val_loss: 0.1669\n",
      "Epoch 186/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.1501 - val_loss: 0.1522\n",
      "Epoch 187/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1369 - val_loss: 0.1393\n",
      "Epoch 188/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1388 - val_loss: 0.1464\n",
      "Epoch 189/300\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.160 - 0s 98us/step - loss: 0.1381 - val_loss: 0.1464\n",
      "Epoch 190/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1285 - val_loss: 0.1382\n",
      "Epoch 191/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1258 - val_loss: 0.1410\n",
      "Epoch 192/300\n",
      "103/103 [==============================] - 0s 78us/step - loss: 0.1269 - val_loss: 0.1382\n",
      "Epoch 193/300\n",
      "103/103 [==============================] - 0s 93us/step - loss: 0.1334 - val_loss: 0.1167\n",
      "Epoch 194/300\n",
      "103/103 [==============================] - 0s 106us/step - loss: 0.1122 - val_loss: 0.1274\n",
      "Epoch 195/300\n",
      "103/103 [==============================] - 0s 152us/step - loss: 0.1280 - val_loss: 0.1289\n",
      "Epoch 196/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1266 - val_loss: 0.1511\n",
      "Epoch 197/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1381 - val_loss: 0.1196\n",
      "Epoch 198/300\n",
      "103/103 [==============================] - 0s 361us/step - loss: 0.1095 - val_loss: 0.1150\n",
      "Epoch 199/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1073 - val_loss: 0.1066\n",
      "Epoch 200/300\n",
      "103/103 [==============================] - 0s 113us/step - loss: 0.0988 - val_loss: 0.1254\n",
      "Epoch 201/300\n",
      "103/103 [==============================] - 0s 117us/step - loss: 0.1152 - val_loss: 0.1139\n",
      "Epoch 202/300\n",
      "103/103 [==============================] - 0s 175us/step - loss: 0.1058 - val_loss: 0.1238\n",
      "Epoch 203/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.1063 - val_loss: 0.1198\n",
      "Epoch 204/300\n",
      "103/103 [==============================] - 0s 146us/step - loss: 0.1044 - val_loss: 0.1218\n",
      "Epoch 205/300\n",
      "103/103 [==============================] - 0s 292us/step - loss: 0.1050 - val_loss: 0.1178\n",
      "Epoch 206/300\n",
      "103/103 [==============================] - 0s 193us/step - loss: 0.1084 - val_loss: 0.1317\n",
      "Epoch 207/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.1130 - val_loss: 0.1235\n",
      "Epoch 208/300\n",
      "103/103 [==============================] - 0s 114us/step - loss: 0.1128 - val_loss: 0.1324\n",
      "Epoch 209/300\n",
      "103/103 [==============================] - 0s 103us/step - loss: 0.1242 - val_loss: 0.1482\n",
      "Epoch 210/300\n",
      "103/103 [==============================] - 0s 95us/step - loss: 0.1298 - val_loss: 0.1345\n",
      "Epoch 211/300\n",
      "103/103 [==============================] - 0s 159us/step - loss: 0.1174 - val_loss: 0.1388\n",
      "Epoch 212/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1190 - val_loss: 0.1248\n",
      "Epoch 213/300\n",
      "103/103 [==============================] - 0s 145us/step - loss: 0.1189 - val_loss: 0.1324\n",
      "Epoch 214/300\n",
      "103/103 [==============================] - 0s 146us/step - loss: 0.1252 - val_loss: 0.1209\n",
      "Epoch 215/300\n",
      "103/103 [==============================] - 0s 185us/step - loss: 0.1190 - val_loss: 0.1233\n",
      "Epoch 216/300\n",
      "103/103 [==============================] - 0s 126us/step - loss: 0.1160 - val_loss: 0.1237\n",
      "Epoch 217/300\n",
      "103/103 [==============================] - 0s 161us/step - loss: 0.1179 - val_loss: 0.1335\n",
      "Epoch 218/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.1219 - val_loss: 0.1456\n",
      "Epoch 219/300\n",
      "103/103 [==============================] - 0s 120us/step - loss: 0.1307 - val_loss: 0.1418\n",
      "Epoch 220/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.1187 - val_loss: 0.1270\n",
      "Epoch 221/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1163 - val_loss: 0.1340\n",
      "Epoch 222/300\n",
      "103/103 [==============================] - 0s 117us/step - loss: 0.1234 - val_loss: 0.1238\n",
      "Epoch 223/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1163 - val_loss: 0.1210\n",
      "Epoch 224/300\n",
      "103/103 [==============================] - 0s 104us/step - loss: 0.1089 - val_loss: 0.1209\n",
      "Epoch 225/300\n",
      "103/103 [==============================] - 0s 180us/step - loss: 0.1128 - val_loss: 0.1150\n",
      "Epoch 226/300\n",
      "103/103 [==============================] - 0s 123us/step - loss: 0.1013 - val_loss: 0.1116\n",
      "Epoch 227/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.1071 - val_loss: 0.1276\n",
      "Epoch 228/300\n",
      "103/103 [==============================] - 0s 166us/step - loss: 0.1121 - val_loss: 0.1427\n",
      "Epoch 229/300\n",
      "103/103 [==============================] - 0s 86us/step - loss: 0.1315 - val_loss: 0.1537\n",
      "Epoch 230/300\n",
      "103/103 [==============================] - 0s 119us/step - loss: 0.1400 - val_loss: 0.1266\n",
      "Epoch 231/300\n",
      "103/103 [==============================] - 0s 139us/step - loss: 0.1212 - val_loss: 0.1321\n",
      "Epoch 232/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.1141 - val_loss: 0.1130\n",
      "Epoch 233/300\n",
      "103/103 [==============================] - 0s 120us/step - loss: 0.1064 - val_loss: 0.1270\n",
      "Epoch 234/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1080 - val_loss: 0.1152\n",
      "Epoch 235/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 119us/step - loss: 0.1098 - val_loss: 0.1140\n",
      "Epoch 236/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1041 - val_loss: 0.1183\n",
      "Epoch 237/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1058 - val_loss: 0.1236\n",
      "Epoch 238/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1169 - val_loss: 0.1261\n",
      "Epoch 239/300\n",
      "103/103 [==============================] - 0s 136us/step - loss: 0.1175 - val_loss: 0.1308\n",
      "Epoch 240/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1139 - val_loss: 0.1202\n",
      "Epoch 241/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1127 - val_loss: 0.1295\n",
      "Epoch 242/300\n",
      "103/103 [==============================] - 0s 96us/step - loss: 0.1107 - val_loss: 0.1235\n",
      "Epoch 243/300\n",
      "103/103 [==============================] - 0s 106us/step - loss: 0.1119 - val_loss: 0.1227\n",
      "Epoch 244/300\n",
      "103/103 [==============================] - 0s 110us/step - loss: 0.1065 - val_loss: 0.1260\n",
      "Epoch 245/300\n",
      "103/103 [==============================] - 0s 98us/step - loss: 0.1164 - val_loss: 0.1226\n",
      "Epoch 246/300\n",
      "103/103 [==============================] - 0s 116us/step - loss: 0.1111 - val_loss: 0.1094\n",
      "Epoch 247/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1060 - val_loss: 0.1333\n",
      "Epoch 248/300\n",
      "103/103 [==============================] - 0s 95us/step - loss: 0.1155 - val_loss: 0.1204\n",
      "Epoch 249/300\n",
      "103/103 [==============================] - 0s 125us/step - loss: 0.1100 - val_loss: 0.1174\n",
      "Epoch 250/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1096 - val_loss: 0.1367\n",
      "Epoch 251/300\n",
      "103/103 [==============================] - 0s 129us/step - loss: 0.1254 - val_loss: 0.1403\n",
      "Epoch 252/300\n",
      "103/103 [==============================] - 0s 106us/step - loss: 0.1223 - val_loss: 0.1415\n",
      "Epoch 253/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.1278 - val_loss: 0.1363\n",
      "Epoch 254/300\n",
      "103/103 [==============================] - 0s 87us/step - loss: 0.1166 - val_loss: 0.1257\n",
      "Epoch 255/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1181 - val_loss: 0.1161\n",
      "Epoch 256/300\n",
      "103/103 [==============================] - 0s 96us/step - loss: 0.1054 - val_loss: 0.1282\n",
      "Epoch 257/300\n",
      "103/103 [==============================] - 0s 224us/step - loss: 0.1187 - val_loss: 0.1288\n",
      "Epoch 258/300\n",
      "103/103 [==============================] - 0s 108us/step - loss: 0.1163 - val_loss: 0.1252\n",
      "Epoch 259/300\n",
      "103/103 [==============================] - 0s 94us/step - loss: 0.1144 - val_loss: 0.1137\n",
      "Epoch 260/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1092 - val_loss: 0.1191\n",
      "Epoch 261/300\n",
      "103/103 [==============================] - 0s 83us/step - loss: 0.1109 - val_loss: 0.1319\n",
      "Epoch 262/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1109 - val_loss: 0.1265\n",
      "Epoch 263/300\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.122 - 0s 97us/step - loss: 0.1101 - val_loss: 0.1137\n",
      "Epoch 264/300\n",
      "103/103 [==============================] - 0s 195us/step - loss: 0.1036 - val_loss: 0.1182\n",
      "Epoch 265/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1095 - val_loss: 0.1281\n",
      "Epoch 266/300\n",
      "103/103 [==============================] - 0s 87us/step - loss: 0.1055 - val_loss: 0.1158\n",
      "Epoch 267/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1067 - val_loss: 0.1129\n",
      "Epoch 268/300\n",
      "103/103 [==============================] - 0s 185us/step - loss: 0.1000 - val_loss: 0.1154\n",
      "Epoch 269/300\n",
      "103/103 [==============================] - 0s 103us/step - loss: 0.1084 - val_loss: 0.1202\n",
      "Epoch 270/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1076 - val_loss: 0.1211\n",
      "Epoch 271/300\n",
      "103/103 [==============================] - 0s 312us/step - loss: 0.1087 - val_loss: 0.1134\n",
      "Epoch 272/300\n",
      "103/103 [==============================] - 0s 127us/step - loss: 0.1158 - val_loss: 0.1318\n",
      "Epoch 273/300\n",
      "103/103 [==============================] - 0s 124us/step - loss: 0.1121 - val_loss: 0.1247\n",
      "Epoch 274/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1064 - val_loss: 0.1169\n",
      "Epoch 275/300\n",
      "103/103 [==============================] - 0s 234us/step - loss: 0.1058 - val_loss: 0.1247\n",
      "Epoch 276/300\n",
      "103/103 [==============================] - 0s 116us/step - loss: 0.1109 - val_loss: 0.1207\n",
      "Epoch 277/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1099 - val_loss: 0.1076\n",
      "Epoch 278/300\n",
      "103/103 [==============================] - 0s 263us/step - loss: 0.1118 - val_loss: 0.1231\n",
      "Epoch 279/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1173 - val_loss: 0.1162\n",
      "Epoch 280/300\n",
      "103/103 [==============================] - 0s 93us/step - loss: 0.1145 - val_loss: 0.1178\n",
      "Epoch 281/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1149 - val_loss: 0.1290\n",
      "Epoch 282/300\n",
      "103/103 [==============================] - 0s 98us/step - loss: 0.1225 - val_loss: 0.1297\n",
      "Epoch 283/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1207 - val_loss: 0.1233\n",
      "Epoch 284/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1098 - val_loss: 0.1153\n",
      "Epoch 285/300\n",
      "103/103 [==============================] - 0s 108us/step - loss: 0.1026 - val_loss: 0.1178\n",
      "Epoch 286/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1057 - val_loss: 0.1167\n",
      "Epoch 287/300\n",
      "103/103 [==============================] - 0s 107us/step - loss: 0.1048 - val_loss: 0.1212\n",
      "Epoch 288/300\n",
      "103/103 [==============================] - 0s 91us/step - loss: 0.1135 - val_loss: 0.1404\n",
      "Epoch 289/300\n",
      "103/103 [==============================] - 0s 89us/step - loss: 0.1259 - val_loss: 0.1374\n",
      "Epoch 290/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1372 - val_loss: 0.1396\n",
      "Epoch 291/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1323 - val_loss: 0.1243\n",
      "Epoch 292/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1157 - val_loss: 0.1231\n",
      "Epoch 293/300\n",
      "103/103 [==============================] - 0s 91us/step - loss: 0.1136 - val_loss: 0.1367\n",
      "Epoch 294/300\n",
      "103/103 [==============================] - 0s 87us/step - loss: 0.1200 - val_loss: 0.1362\n",
      "Epoch 295/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1240 - val_loss: 0.1224\n",
      "Epoch 296/300\n",
      "103/103 [==============================] - 0s 93us/step - loss: 0.1160 - val_loss: 0.1464\n",
      "Epoch 297/300\n",
      "103/103 [==============================] - 0s 135us/step - loss: 0.1332 - val_loss: 0.1353\n",
      "Epoch 298/300\n",
      "103/103 [==============================] - 0s 88us/step - loss: 0.1221 - val_loss: 0.1286\n",
      "Epoch 299/300\n",
      "103/103 [==============================] - 0s 97us/step - loss: 0.1163 - val_loss: 0.1332\n",
      "Epoch 300/300\n",
      "103/103 [==============================] - 0s 87us/step - loss: 0.1192 - val_loss: 0.1240\n"
     ]
    }
   ],
   "source": [
    "i=3;\n",
    "j=6;\n",
    "\n",
    "model0 = Sequential()\n",
    "model0.add(Dense(10, input_shape=(10,), use_bias=True, kernel_initializer='random_uniform', activation='tanh', kernel_regularizer=regularizers.l2(0.2*j),activity_regularizer=regularizers.l1(1)))\n",
    "model0.add(Dropout(0.1*i))\n",
    "model0.add(Dense(4, use_bias=True, kernel_initializer='random_uniform', activation='tanh'))\n",
    "model0.output_shape\n",
    "model0.compile(loss='mean_absolute_error',\n",
    "              optimizer='adam')\n",
    "hist=model0.fit(X_train, y_train, epochs=300, batch_size=16, validation_split=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x205587b5c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector=np.arange(300)\n",
    "plt.plot(vector,hist.history['loss'],label='training loss')\n",
    "plt.plot(vector,hist.history['val_loss'], label='validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Mean absolute error')\n",
    "plt.legend()\n",
    "# plt.savefig('Training and Validation Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.047916452161955"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean absolute percentage error, on the test data set\n",
    "\n",
    "np.mean(abs(y_test-model0.predict(X_test))/y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.predict(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12397211446211888"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['val_loss'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "(10,)\n",
      "(10, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "for i in range(4):\n",
    "    print(np.asanyarray(model0.get_weights()[i]).squeeze().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Trying IEX Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IEX can give us \n",
    "\n",
    "def getStockPrice5yr(StockAbbrev):\n",
    "    url='https://api.iextrading.com/1.0'\n",
    "    response=requests.get(url+'/stock/'+StockAbbrev + '/chart/5y')\n",
    "    data_df=pd.DataFrame.from_dict(response.json())\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIS_df=getStockPrice5yr('DIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIS_df.set_index('date',drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-03-06\n",
      "2013-03-07\n",
      "2013-03-08\n",
      "2013-03-11\n",
      "2013-03-12\n",
      "2013-03-13\n",
      "2013-03-14\n",
      "2013-03-15\n",
      "2013-03-18\n",
      "2013-03-19\n",
      "2013-03-20\n",
      "2013-03-21\n",
      "2013-03-22\n",
      "2013-03-25\n",
      "2013-03-26\n",
      "2013-03-27\n",
      "2013-03-28\n",
      "2013-04-01\n",
      "2013-04-02\n",
      "2013-04-03\n",
      "2013-04-04\n",
      "2013-04-05\n",
      "2013-04-08\n",
      "2013-04-09\n",
      "2013-04-10\n",
      "2013-04-11\n",
      "2013-04-12\n",
      "2013-04-15\n",
      "2013-04-16\n",
      "2013-04-17\n",
      "2013-04-18\n",
      "2013-04-19\n",
      "2013-04-22\n",
      "2013-04-23\n",
      "2013-04-24\n",
      "2013-04-25\n",
      "2013-04-26\n",
      "2013-04-29\n",
      "2013-04-30\n",
      "2013-05-01\n",
      "2013-05-02\n",
      "2013-05-03\n",
      "2013-05-06\n",
      "2013-05-07\n",
      "2013-05-08\n",
      "2013-05-09\n",
      "2013-05-10\n",
      "2013-05-13\n",
      "2013-05-14\n",
      "2013-05-15\n",
      "2013-05-16\n",
      "2013-05-17\n",
      "2013-05-20\n",
      "2013-05-21\n",
      "2013-05-22\n",
      "2013-05-23\n",
      "2013-05-24\n",
      "2013-05-28\n",
      "2013-05-29\n",
      "2013-05-30\n",
      "2013-05-31\n",
      "2013-06-03\n",
      "2013-06-04\n",
      "2013-06-05\n",
      "2013-06-06\n",
      "2013-06-07\n",
      "2013-06-10\n",
      "2013-06-11\n",
      "2013-06-12\n",
      "2013-06-13\n",
      "2013-06-14\n",
      "2013-06-17\n",
      "2013-06-18\n",
      "2013-06-19\n",
      "2013-06-20\n",
      "2013-06-21\n",
      "2013-06-24\n",
      "2013-06-25\n",
      "2013-06-26\n",
      "2013-06-27\n",
      "2013-06-28\n",
      "2013-07-01\n",
      "2013-07-02\n",
      "2013-07-03\n",
      "2013-07-05\n",
      "2013-07-08\n",
      "2013-07-09\n",
      "2013-07-10\n",
      "2013-07-11\n",
      "2013-07-12\n",
      "2013-07-15\n",
      "2013-07-16\n",
      "2013-07-17\n",
      "2013-07-18\n",
      "2013-07-19\n",
      "2013-07-22\n",
      "2013-07-23\n",
      "2013-07-24\n",
      "2013-07-25\n",
      "2013-07-26\n",
      "2013-07-29\n",
      "2013-07-30\n",
      "2013-07-31\n",
      "2013-08-01\n",
      "2013-08-02\n",
      "2013-08-05\n",
      "2013-08-06\n",
      "2013-08-07\n",
      "2013-08-08\n",
      "2013-08-09\n",
      "2013-08-12\n",
      "2013-08-13\n",
      "2013-08-14\n",
      "2013-08-15\n",
      "2013-08-16\n",
      "2013-08-19\n",
      "2013-08-20\n",
      "2013-08-21\n",
      "2013-08-22\n",
      "2013-08-23\n",
      "2013-08-26\n",
      "2013-08-27\n",
      "2013-08-28\n",
      "2013-08-29\n",
      "2013-08-30\n",
      "2013-09-03\n",
      "2013-09-04\n",
      "2013-09-05\n",
      "2013-09-06\n",
      "2013-09-09\n",
      "2013-09-10\n",
      "2013-09-11\n",
      "2013-09-12\n",
      "2013-09-13\n",
      "2013-09-16\n",
      "2013-09-17\n",
      "2013-09-18\n",
      "2013-09-19\n",
      "2013-09-20\n",
      "2013-09-23\n",
      "2013-09-24\n",
      "2013-09-25\n",
      "2013-09-26\n",
      "2013-09-27\n",
      "2013-09-30\n",
      "2013-10-01\n",
      "2013-10-02\n",
      "2013-10-03\n",
      "2013-10-04\n",
      "2013-10-07\n",
      "2013-10-08\n",
      "2013-10-09\n",
      "2013-10-10\n",
      "2013-10-11\n",
      "2013-10-14\n",
      "2013-10-15\n",
      "2013-10-16\n",
      "2013-10-17\n",
      "2013-10-18\n",
      "2013-10-21\n",
      "2013-10-22\n",
      "2013-10-23\n",
      "2013-10-24\n",
      "2013-10-25\n",
      "2013-10-28\n",
      "2013-10-29\n",
      "2013-10-30\n",
      "2013-10-31\n",
      "2013-11-01\n",
      "2013-11-04\n",
      "2013-11-05\n",
      "2013-11-06\n",
      "2013-11-07\n",
      "2013-11-08\n",
      "2013-11-11\n",
      "2013-11-12\n",
      "2013-11-13\n",
      "2013-11-14\n",
      "2013-11-15\n",
      "2013-11-18\n",
      "2013-11-19\n",
      "2013-11-20\n",
      "2013-11-21\n",
      "2013-11-22\n",
      "2013-11-25\n",
      "2013-11-26\n",
      "2013-11-27\n",
      "2013-11-29\n",
      "2013-12-02\n",
      "2013-12-03\n",
      "2013-12-04\n",
      "2013-12-05\n",
      "2013-12-06\n",
      "2013-12-09\n",
      "2013-12-10\n",
      "2013-12-11\n",
      "2013-12-12\n",
      "2013-12-13\n",
      "2013-12-16\n",
      "2013-12-17\n",
      "2013-12-18\n",
      "2013-12-19\n",
      "2013-12-20\n",
      "2013-12-23\n",
      "2013-12-24\n",
      "2013-12-26\n",
      "2013-12-27\n",
      "2013-12-30\n",
      "2013-12-31\n",
      "2014-01-02\n",
      "2014-01-03\n",
      "2014-01-06\n",
      "2014-01-07\n",
      "2014-01-08\n",
      "2014-01-09\n",
      "2014-01-10\n",
      "2014-01-13\n",
      "2014-01-14\n",
      "2014-01-15\n",
      "2014-01-16\n",
      "2014-01-17\n",
      "2014-01-21\n",
      "2014-01-22\n",
      "2014-01-23\n",
      "2014-01-24\n",
      "2014-01-27\n",
      "2014-01-28\n",
      "2014-01-29\n",
      "2014-01-30\n",
      "2014-01-31\n",
      "2014-02-03\n",
      "2014-02-04\n",
      "2014-02-05\n",
      "2014-02-06\n",
      "2014-02-07\n",
      "2014-02-10\n",
      "2014-02-11\n",
      "2014-02-12\n",
      "2014-02-13\n",
      "2014-02-14\n",
      "2014-02-18\n",
      "2014-02-19\n",
      "2014-02-20\n",
      "2014-02-21\n",
      "2014-02-24\n",
      "2014-02-25\n",
      "2014-02-26\n",
      "2014-02-27\n",
      "2014-02-28\n",
      "2014-03-03\n",
      "2014-03-04\n",
      "2014-03-05\n",
      "2014-03-06\n",
      "2014-03-07\n",
      "2014-03-10\n",
      "2014-03-11\n",
      "2014-03-12\n",
      "2014-03-13\n",
      "2014-03-14\n",
      "2014-03-17\n",
      "2014-03-18\n",
      "2014-03-19\n",
      "2014-03-20\n",
      "2014-03-21\n",
      "2014-03-24\n",
      "2014-03-25\n",
      "2014-03-26\n",
      "2014-03-27\n",
      "2014-03-28\n",
      "2014-03-31\n",
      "2014-04-01\n",
      "2014-04-02\n",
      "2014-04-03\n",
      "2014-04-04\n",
      "2014-04-07\n",
      "2014-04-08\n",
      "2014-04-09\n",
      "2014-04-10\n",
      "2014-04-11\n",
      "2014-04-14\n",
      "2014-04-15\n",
      "2014-04-16\n",
      "2014-04-17\n",
      "2014-04-21\n",
      "2014-04-22\n",
      "2014-04-23\n",
      "2014-04-24\n",
      "2014-04-25\n",
      "2014-04-28\n",
      "2014-04-29\n",
      "2014-04-30\n",
      "2014-05-01\n",
      "2014-05-02\n",
      "2014-05-05\n",
      "2014-05-06\n",
      "2014-05-07\n",
      "2014-05-08\n",
      "2014-05-09\n",
      "2014-05-12\n",
      "2014-05-13\n",
      "2014-05-14\n",
      "2014-05-15\n",
      "2014-05-16\n",
      "2014-05-19\n",
      "2014-05-20\n",
      "2014-05-21\n",
      "2014-05-22\n",
      "2014-05-23\n",
      "2014-05-27\n",
      "2014-05-28\n",
      "2014-05-29\n",
      "2014-05-30\n",
      "2014-06-02\n",
      "2014-06-03\n",
      "2014-06-04\n",
      "2014-06-05\n",
      "2014-06-06\n",
      "2014-06-09\n",
      "2014-06-10\n",
      "2014-06-11\n",
      "2014-06-12\n",
      "2014-06-13\n",
      "2014-06-16\n",
      "2014-06-17\n",
      "2014-06-18\n",
      "2014-06-19\n",
      "2014-06-20\n",
      "2014-06-23\n",
      "2014-06-24\n",
      "2014-06-25\n",
      "2014-06-26\n",
      "2014-06-27\n",
      "2014-06-30\n",
      "2014-07-01\n",
      "2014-07-02\n",
      "2014-07-03\n",
      "2014-07-07\n",
      "2014-07-08\n",
      "2014-07-09\n",
      "2014-07-10\n",
      "2014-07-11\n",
      "2014-07-14\n",
      "2014-07-15\n",
      "2014-07-16\n",
      "2014-07-17\n",
      "2014-07-18\n",
      "2014-07-21\n",
      "2014-07-22\n",
      "2014-07-23\n",
      "2014-07-24\n",
      "2014-07-25\n",
      "2014-07-28\n",
      "2014-07-29\n",
      "2014-07-30\n",
      "2014-07-31\n",
      "2014-08-01\n",
      "2014-08-04\n",
      "2014-08-05\n",
      "2014-08-06\n",
      "2014-08-07\n",
      "2014-08-08\n",
      "2014-08-11\n",
      "2014-08-12\n",
      "2014-08-13\n",
      "2014-08-14\n",
      "2014-08-15\n",
      "2014-08-18\n",
      "2014-08-19\n",
      "2014-08-20\n",
      "2014-08-21\n",
      "2014-08-22\n",
      "2014-08-25\n",
      "2014-08-26\n",
      "2014-08-27\n",
      "2014-08-28\n",
      "2014-08-29\n",
      "2014-09-02\n",
      "2014-09-03\n",
      "2014-09-04\n",
      "2014-09-05\n",
      "2014-09-08\n",
      "2014-09-09\n",
      "2014-09-10\n",
      "2014-09-11\n",
      "2014-09-12\n",
      "2014-09-15\n",
      "2014-09-16\n",
      "2014-09-17\n",
      "2014-09-18\n",
      "2014-09-19\n",
      "2014-09-22\n",
      "2014-09-23\n",
      "2014-09-24\n",
      "2014-09-25\n",
      "2014-09-26\n",
      "2014-09-29\n",
      "2014-09-30\n",
      "2014-10-01\n",
      "2014-10-02\n",
      "2014-10-03\n",
      "2014-10-06\n",
      "2014-10-07\n",
      "2014-10-08\n",
      "2014-10-09\n",
      "2014-10-10\n",
      "2014-10-13\n",
      "2014-10-14\n",
      "2014-10-15\n",
      "2014-10-16\n",
      "2014-10-17\n",
      "2014-10-20\n",
      "2014-10-21\n",
      "2014-10-22\n",
      "2014-10-23\n",
      "2014-10-24\n",
      "2014-10-27\n",
      "2014-10-28\n",
      "2014-10-29\n",
      "2014-10-30\n",
      "2014-10-31\n",
      "2014-11-03\n",
      "2014-11-04\n",
      "2014-11-05\n",
      "2014-11-06\n",
      "2014-11-07\n",
      "2014-11-10\n",
      "2014-11-11\n",
      "2014-11-12\n",
      "2014-11-13\n",
      "2014-11-14\n",
      "2014-11-17\n",
      "2014-11-18\n",
      "2014-11-19\n",
      "2014-11-20\n",
      "2014-11-21\n",
      "2014-11-24\n",
      "2014-11-25\n",
      "2014-11-26\n",
      "2014-11-28\n",
      "2014-12-01\n",
      "2014-12-02\n",
      "2014-12-03\n",
      "2014-12-04\n",
      "2014-12-05\n",
      "2014-12-08\n",
      "2014-12-09\n",
      "2014-12-10\n",
      "2014-12-11\n",
      "2014-12-12\n",
      "2014-12-15\n",
      "2014-12-16\n",
      "2014-12-17\n",
      "2014-12-18\n",
      "2014-12-19\n",
      "2014-12-22\n",
      "2014-12-23\n",
      "2014-12-24\n",
      "2014-12-26\n",
      "2014-12-29\n",
      "2014-12-30\n",
      "2014-12-31\n",
      "2015-01-02\n",
      "2015-01-05\n",
      "2015-01-06\n",
      "2015-01-07\n",
      "2015-01-08\n",
      "2015-01-09\n",
      "2015-01-12\n",
      "2015-01-13\n",
      "2015-01-14\n",
      "2015-01-15\n",
      "2015-01-16\n",
      "2015-01-20\n",
      "2015-01-21\n",
      "2015-01-22\n",
      "2015-01-23\n",
      "2015-01-26\n",
      "2015-01-27\n",
      "2015-01-28\n",
      "2015-01-29\n",
      "2015-01-30\n",
      "2015-02-02\n",
      "2015-02-03\n",
      "2015-02-04\n",
      "2015-02-05\n",
      "2015-02-06\n",
      "2015-02-09\n",
      "2015-02-10\n",
      "2015-02-11\n",
      "2015-02-12\n",
      "2015-02-13\n",
      "2015-02-17\n",
      "2015-02-18\n",
      "2015-02-19\n",
      "2015-02-20\n",
      "2015-02-23\n",
      "2015-02-24\n",
      "2015-02-25\n",
      "2015-02-26\n",
      "2015-02-27\n",
      "2015-03-02\n",
      "2015-03-03\n",
      "2015-03-04\n",
      "2015-03-05\n",
      "2015-03-06\n",
      "2015-03-09\n",
      "2015-03-10\n",
      "2015-03-11\n",
      "2015-03-12\n",
      "2015-03-13\n",
      "2015-03-16\n",
      "2015-03-17\n",
      "2015-03-18\n",
      "2015-03-19\n",
      "2015-03-20\n",
      "2015-03-23\n",
      "2015-03-24\n",
      "2015-03-25\n",
      "2015-03-26\n",
      "2015-03-27\n",
      "2015-03-30\n",
      "2015-03-31\n",
      "2015-04-01\n",
      "2015-04-02\n",
      "2015-04-06\n",
      "2015-04-07\n",
      "2015-04-08\n",
      "2015-04-09\n",
      "2015-04-10\n",
      "2015-04-13\n",
      "2015-04-14\n",
      "2015-04-15\n",
      "2015-04-16\n",
      "2015-04-17\n",
      "2015-04-20\n",
      "2015-04-21\n",
      "2015-04-22\n",
      "2015-04-23\n",
      "2015-04-24\n",
      "2015-04-27\n",
      "2015-04-28\n",
      "2015-04-29\n",
      "2015-04-30\n",
      "2015-05-01\n",
      "2015-05-04\n",
      "2015-05-05\n",
      "2015-05-06\n",
      "2015-05-07\n",
      "2015-05-08\n",
      "2015-05-11\n",
      "2015-05-12\n",
      "2015-05-13\n",
      "2015-05-14\n",
      "2015-05-15\n",
      "2015-05-18\n",
      "2015-05-19\n",
      "2015-05-20\n",
      "2015-05-21\n",
      "2015-05-22\n",
      "2015-05-26\n",
      "2015-05-27\n",
      "2015-05-28\n",
      "2015-05-29\n",
      "2015-06-01\n",
      "2015-06-02\n",
      "2015-06-03\n",
      "2015-06-04\n",
      "2015-06-05\n",
      "2015-06-08\n",
      "2015-06-09\n",
      "2015-06-10\n",
      "2015-06-11\n",
      "2015-06-12\n",
      "2015-06-15\n",
      "2015-06-16\n",
      "2015-06-17\n",
      "2015-06-18\n",
      "2015-06-19\n",
      "2015-06-22\n",
      "2015-06-23\n",
      "2015-06-24\n",
      "2015-06-25\n",
      "2015-06-26\n",
      "2015-06-29\n",
      "2015-06-30\n",
      "2015-07-01\n",
      "2015-07-02\n",
      "2015-07-06\n",
      "2015-07-07\n",
      "2015-07-08\n",
      "2015-07-09\n",
      "2015-07-10\n",
      "2015-07-13\n",
      "2015-07-14\n",
      "2015-07-15\n",
      "2015-07-16\n",
      "2015-07-17\n",
      "2015-07-20\n",
      "2015-07-21\n",
      "2015-07-22\n",
      "2015-07-23\n",
      "2015-07-24\n",
      "2015-07-27\n",
      "2015-07-28\n",
      "2015-07-29\n",
      "2015-07-30\n",
      "2015-07-31\n",
      "2015-08-03\n",
      "2015-08-04\n",
      "2015-08-05\n",
      "2015-08-06\n",
      "2015-08-07\n",
      "2015-08-10\n",
      "2015-08-11\n",
      "2015-08-12\n",
      "2015-08-13\n",
      "2015-08-14\n",
      "2015-08-17\n",
      "2015-08-18\n",
      "2015-08-19\n",
      "2015-08-20\n",
      "2015-08-21\n",
      "2015-08-24\n",
      "2015-08-25\n",
      "2015-08-26\n",
      "2015-08-27\n",
      "2015-08-28\n",
      "2015-08-31\n",
      "2015-09-01\n",
      "2015-09-02\n",
      "2015-09-03\n",
      "2015-09-04\n",
      "2015-09-08\n",
      "2015-09-09\n",
      "2015-09-10\n",
      "2015-09-11\n",
      "2015-09-14\n",
      "2015-09-15\n",
      "2015-09-16\n",
      "2015-09-17\n",
      "2015-09-18\n",
      "2015-09-21\n",
      "2015-09-22\n",
      "2015-09-23\n",
      "2015-09-24\n",
      "2015-09-25\n",
      "2015-09-28\n",
      "2015-09-29\n",
      "2015-09-30\n",
      "2015-10-01\n",
      "2015-10-02\n",
      "2015-10-05\n",
      "2015-10-06\n",
      "2015-10-07\n",
      "2015-10-08\n",
      "2015-10-09\n",
      "2015-10-12\n",
      "2015-10-13\n",
      "2015-10-14\n",
      "2015-10-15\n",
      "2015-10-16\n",
      "2015-10-19\n",
      "2015-10-20\n",
      "2015-10-21\n",
      "2015-10-22\n",
      "2015-10-23\n",
      "2015-10-26\n",
      "2015-10-27\n",
      "2015-10-28\n",
      "2015-10-29\n",
      "2015-10-30\n",
      "2015-11-02\n",
      "2015-11-03\n",
      "2015-11-04\n",
      "2015-11-05\n",
      "2015-11-06\n",
      "2015-11-09\n",
      "2015-11-10\n",
      "2015-11-11\n",
      "2015-11-12\n",
      "2015-11-13\n",
      "2015-11-16\n",
      "2015-11-17\n",
      "2015-11-18\n",
      "2015-11-19\n",
      "2015-11-20\n",
      "2015-11-23\n",
      "2015-11-24\n",
      "2015-11-25\n",
      "2015-11-27\n",
      "2015-11-30\n",
      "2015-12-01\n",
      "2015-12-02\n",
      "2015-12-03\n",
      "2015-12-04\n",
      "2015-12-07\n",
      "2015-12-08\n",
      "2015-12-09\n",
      "2015-12-10\n",
      "2015-12-11\n",
      "2015-12-14\n",
      "2015-12-15\n",
      "2015-12-16\n",
      "2015-12-17\n",
      "2015-12-18\n",
      "2015-12-21\n",
      "2015-12-22\n",
      "2015-12-23\n",
      "2015-12-24\n",
      "2015-12-28\n",
      "2015-12-29\n",
      "2015-12-30\n",
      "2015-12-31\n",
      "2016-01-04\n",
      "2016-01-05\n",
      "2016-01-06\n",
      "2016-01-07\n",
      "2016-01-08\n",
      "2016-01-11\n",
      "2016-01-12\n",
      "2016-01-13\n",
      "2016-01-14\n",
      "2016-01-15\n",
      "2016-01-19\n",
      "2016-01-20\n",
      "2016-01-21\n",
      "2016-01-22\n",
      "2016-01-25\n",
      "2016-01-26\n",
      "2016-01-27\n",
      "2016-01-28\n",
      "2016-01-29\n",
      "2016-02-01\n",
      "2016-02-02\n",
      "2016-02-03\n",
      "2016-02-04\n",
      "2016-02-05\n",
      "2016-02-08\n",
      "2016-02-09\n",
      "2016-02-10\n",
      "2016-02-11\n",
      "2016-02-12\n",
      "2016-02-16\n",
      "2016-02-17\n",
      "2016-02-18\n",
      "2016-02-19\n",
      "2016-02-22\n",
      "2016-02-23\n",
      "2016-02-24\n",
      "2016-02-25\n",
      "2016-02-26\n",
      "2016-02-29\n",
      "2016-03-01\n",
      "2016-03-02\n",
      "2016-03-03\n",
      "2016-03-04\n",
      "2016-03-07\n",
      "2016-03-08\n",
      "2016-03-09\n",
      "2016-03-10\n",
      "2016-03-11\n",
      "2016-03-14\n",
      "2016-03-15\n",
      "2016-03-16\n",
      "2016-03-17\n",
      "2016-03-18\n",
      "2016-03-21\n",
      "2016-03-22\n",
      "2016-03-23\n",
      "2016-03-24\n",
      "2016-03-28\n",
      "2016-03-29\n",
      "2016-03-30\n",
      "2016-03-31\n",
      "2016-04-01\n",
      "2016-04-04\n",
      "2016-04-05\n",
      "2016-04-06\n",
      "2016-04-07\n",
      "2016-04-08\n",
      "2016-04-11\n",
      "2016-04-12\n",
      "2016-04-13\n",
      "2016-04-14\n",
      "2016-04-15\n",
      "2016-04-18\n",
      "2016-04-19\n",
      "2016-04-20\n",
      "2016-04-21\n",
      "2016-04-22\n",
      "2016-04-25\n",
      "2016-04-26\n",
      "2016-04-27\n",
      "2016-04-28\n",
      "2016-04-29\n",
      "2016-05-02\n",
      "2016-05-03\n",
      "2016-05-04\n",
      "2016-05-05\n",
      "2016-05-06\n",
      "2016-05-09\n",
      "2016-05-10\n",
      "2016-05-11\n",
      "2016-05-12\n",
      "2016-05-13\n",
      "2016-05-16\n",
      "2016-05-17\n",
      "2016-05-18\n",
      "2016-05-19\n",
      "2016-05-20\n",
      "2016-05-23\n",
      "2016-05-24\n",
      "2016-05-25\n",
      "2016-05-26\n",
      "2016-05-27\n",
      "2016-05-31\n",
      "2016-06-01\n",
      "2016-06-02\n",
      "2016-06-03\n",
      "2016-06-06\n",
      "2016-06-07\n",
      "2016-06-08\n",
      "2016-06-09\n",
      "2016-06-10\n",
      "2016-06-13\n",
      "2016-06-14\n",
      "2016-06-15\n",
      "2016-06-16\n",
      "2016-06-17\n",
      "2016-06-20\n",
      "2016-06-21\n",
      "2016-06-22\n",
      "2016-06-23\n",
      "2016-06-24\n",
      "2016-06-27\n",
      "2016-06-28\n",
      "2016-06-29\n",
      "2016-06-30\n",
      "2016-07-01\n",
      "2016-07-05\n",
      "2016-07-06\n",
      "2016-07-07\n",
      "2016-07-08\n",
      "2016-07-11\n",
      "2016-07-12\n",
      "2016-07-13\n",
      "2016-07-14\n",
      "2016-07-15\n",
      "2016-07-18\n",
      "2016-07-19\n",
      "2016-07-20\n",
      "2016-07-21\n",
      "2016-07-22\n",
      "2016-07-25\n",
      "2016-07-26\n",
      "2016-07-27\n",
      "2016-07-28\n",
      "2016-07-29\n",
      "2016-08-01\n",
      "2016-08-02\n",
      "2016-08-03\n",
      "2016-08-04\n",
      "2016-08-05\n",
      "2016-08-08\n",
      "2016-08-09\n",
      "2016-08-10\n",
      "2016-08-11\n",
      "2016-08-12\n",
      "2016-08-15\n",
      "2016-08-16\n",
      "2016-08-17\n",
      "2016-08-18\n",
      "2016-08-19\n",
      "2016-08-22\n",
      "2016-08-23\n",
      "2016-08-24\n",
      "2016-08-25\n",
      "2016-08-26\n",
      "2016-08-29\n",
      "2016-08-30\n",
      "2016-08-31\n",
      "2016-09-01\n",
      "2016-09-02\n",
      "2016-09-06\n",
      "2016-09-07\n",
      "2016-09-08\n",
      "2016-09-09\n",
      "2016-09-12\n",
      "2016-09-13\n",
      "2016-09-14\n",
      "2016-09-15\n",
      "2016-09-16\n",
      "2016-09-19\n",
      "2016-09-20\n",
      "2016-09-21\n",
      "2016-09-22\n",
      "2016-09-23\n",
      "2016-09-26\n",
      "2016-09-27\n",
      "2016-09-28\n",
      "2016-09-29\n",
      "2016-09-30\n",
      "2016-10-03\n",
      "2016-10-04\n",
      "2016-10-05\n",
      "2016-10-06\n",
      "2016-10-07\n",
      "2016-10-10\n",
      "2016-10-11\n",
      "2016-10-12\n",
      "2016-10-13\n",
      "2016-10-14\n",
      "2016-10-17\n",
      "2016-10-18\n",
      "2016-10-19\n",
      "2016-10-20\n",
      "2016-10-21\n",
      "2016-10-24\n",
      "2016-10-25\n",
      "2016-10-26\n",
      "2016-10-27\n",
      "2016-10-28\n",
      "2016-10-31\n",
      "2016-11-01\n",
      "2016-11-02\n",
      "2016-11-03\n",
      "2016-11-04\n",
      "2016-11-07\n",
      "2016-11-08\n",
      "2016-11-09\n",
      "2016-11-10\n",
      "2016-11-11\n",
      "2016-11-14\n",
      "2016-11-15\n",
      "2016-11-16\n",
      "2016-11-17\n",
      "2016-11-18\n",
      "2016-11-21\n",
      "2016-11-22\n",
      "2016-11-23\n",
      "2016-11-25\n",
      "2016-11-28\n",
      "2016-11-29\n",
      "2016-11-30\n",
      "2016-12-01\n",
      "2016-12-02\n",
      "2016-12-05\n",
      "2016-12-06\n",
      "2016-12-07\n",
      "2016-12-08\n",
      "2016-12-09\n",
      "2016-12-12\n",
      "2016-12-13\n",
      "2016-12-14\n",
      "2016-12-15\n",
      "2016-12-16\n",
      "2016-12-19\n",
      "2016-12-20\n",
      "2016-12-21\n",
      "2016-12-22\n",
      "2016-12-23\n",
      "2016-12-27\n",
      "2016-12-28\n",
      "2016-12-29\n",
      "2016-12-30\n",
      "2017-01-03\n",
      "2017-01-04\n",
      "2017-01-05\n",
      "2017-01-06\n",
      "2017-01-09\n",
      "2017-01-10\n",
      "2017-01-11\n",
      "2017-01-12\n",
      "2017-01-13\n",
      "2017-01-17\n",
      "2017-01-18\n",
      "2017-01-19\n",
      "2017-01-20\n",
      "2017-01-23\n",
      "2017-01-24\n",
      "2017-01-25\n",
      "2017-01-26\n",
      "2017-01-27\n",
      "2017-01-30\n",
      "2017-01-31\n",
      "2017-02-01\n",
      "2017-02-02\n",
      "2017-02-03\n",
      "2017-02-06\n",
      "2017-02-07\n",
      "2017-02-08\n",
      "2017-02-09\n",
      "2017-02-10\n",
      "2017-02-13\n",
      "2017-02-14\n",
      "2017-02-15\n",
      "2017-02-16\n",
      "2017-02-17\n",
      "2017-02-21\n",
      "2017-02-22\n",
      "2017-02-23\n",
      "2017-02-24\n",
      "2017-02-27\n",
      "2017-02-28\n",
      "2017-03-01\n",
      "2017-03-02\n",
      "2017-03-03\n",
      "2017-03-06\n",
      "2017-03-07\n",
      "2017-03-08\n",
      "2017-03-09\n",
      "2017-03-10\n",
      "2017-03-13\n",
      "2017-03-14\n",
      "2017-03-15\n",
      "2017-03-16\n",
      "2017-03-17\n",
      "2017-03-20\n",
      "2017-03-21\n",
      "2017-03-22\n",
      "2017-03-23\n",
      "2017-03-24\n",
      "2017-03-27\n",
      "2017-03-28\n",
      "2017-03-29\n",
      "2017-03-30\n",
      "2017-03-31\n",
      "2017-04-03\n",
      "2017-04-04\n",
      "2017-04-05\n",
      "2017-04-06\n",
      "2017-04-07\n",
      "2017-04-10\n",
      "2017-04-11\n",
      "2017-04-12\n",
      "2017-04-13\n",
      "2017-04-17\n",
      "2017-04-18\n",
      "2017-04-19\n",
      "2017-04-20\n",
      "2017-04-21\n",
      "2017-04-24\n",
      "2017-04-25\n",
      "2017-04-26\n",
      "2017-04-27\n",
      "2017-04-28\n",
      "2017-05-01\n",
      "2017-05-02\n",
      "2017-05-03\n",
      "2017-05-04\n",
      "2017-05-05\n",
      "2017-05-08\n",
      "2017-05-09\n",
      "2017-05-10\n",
      "2017-05-11\n",
      "2017-05-12\n",
      "2017-05-15\n",
      "2017-05-16\n",
      "2017-05-17\n",
      "2017-05-18\n",
      "2017-05-19\n",
      "2017-05-22\n",
      "2017-05-23\n",
      "2017-05-24\n",
      "2017-05-25\n",
      "2017-05-26\n",
      "2017-05-30\n",
      "2017-05-31\n",
      "2017-06-01\n",
      "2017-06-02\n",
      "2017-06-05\n",
      "2017-06-06\n",
      "2017-06-07\n",
      "2017-06-08\n",
      "2017-06-09\n",
      "2017-06-12\n",
      "2017-06-13\n",
      "2017-06-14\n",
      "2017-06-15\n",
      "2017-06-16\n",
      "2017-06-19\n",
      "2017-06-20\n",
      "2017-06-21\n",
      "2017-06-22\n",
      "2017-06-23\n",
      "2017-06-26\n",
      "2017-06-27\n",
      "2017-06-28\n",
      "2017-06-29\n",
      "2017-06-30\n",
      "2017-07-03\n",
      "2017-07-05\n",
      "2017-07-06\n",
      "2017-07-07\n",
      "2017-07-10\n",
      "2017-07-11\n",
      "2017-07-12\n",
      "2017-07-13\n",
      "2017-07-14\n",
      "2017-07-17\n",
      "2017-07-18\n",
      "2017-07-19\n",
      "2017-07-20\n",
      "2017-07-21\n",
      "2017-07-24\n",
      "2017-07-25\n",
      "2017-07-26\n",
      "2017-07-27\n",
      "2017-07-28\n",
      "2017-07-31\n",
      "2017-08-01\n",
      "2017-08-02\n",
      "2017-08-03\n",
      "2017-08-04\n",
      "2017-08-07\n",
      "2017-08-08\n",
      "2017-08-09\n",
      "2017-08-10\n",
      "2017-08-11\n",
      "2017-08-14\n",
      "2017-08-15\n",
      "2017-08-16\n",
      "2017-08-17\n",
      "2017-08-18\n",
      "2017-08-21\n",
      "2017-08-22\n",
      "2017-08-23\n",
      "2017-08-24\n",
      "2017-08-25\n",
      "2017-08-28\n",
      "2017-08-29\n",
      "2017-08-30\n",
      "2017-08-31\n",
      "2017-09-01\n",
      "2017-09-05\n",
      "2017-09-06\n",
      "2017-09-07\n",
      "2017-09-08\n",
      "2017-09-11\n",
      "2017-09-12\n",
      "2017-09-13\n",
      "2017-09-14\n",
      "2017-09-15\n",
      "2017-09-18\n",
      "2017-09-19\n",
      "2017-09-20\n",
      "2017-09-21\n",
      "2017-09-22\n",
      "2017-09-25\n",
      "2017-09-26\n",
      "2017-09-27\n",
      "2017-09-28\n",
      "2017-09-29\n",
      "2017-10-02\n",
      "2017-10-03\n",
      "2017-10-04\n",
      "2017-10-05\n",
      "2017-10-06\n",
      "2017-10-09\n",
      "2017-10-10\n",
      "2017-10-11\n",
      "2017-10-12\n",
      "2017-10-13\n",
      "2017-10-16\n",
      "2017-10-17\n",
      "2017-10-18\n",
      "2017-10-19\n",
      "2017-10-20\n",
      "2017-10-23\n",
      "2017-10-24\n",
      "2017-10-25\n",
      "2017-10-26\n",
      "2017-10-27\n",
      "2017-10-30\n",
      "2017-10-31\n",
      "2017-11-01\n",
      "2017-11-02\n",
      "2017-11-03\n",
      "2017-11-06\n",
      "2017-11-07\n",
      "2017-11-08\n",
      "2017-11-09\n",
      "2017-11-10\n",
      "2017-11-13\n",
      "2017-11-14\n",
      "2017-11-15\n",
      "2017-11-16\n",
      "2017-11-17\n",
      "2017-11-20\n",
      "2017-11-21\n",
      "2017-11-22\n",
      "2017-11-24\n",
      "2017-11-27\n",
      "2017-11-28\n",
      "2017-11-29\n",
      "2017-11-30\n",
      "2017-12-01\n",
      "2017-12-04\n",
      "2017-12-05\n",
      "2017-12-06\n",
      "2017-12-07\n",
      "2017-12-08\n",
      "2017-12-11\n",
      "2017-12-12\n",
      "2017-12-13\n",
      "2017-12-14\n",
      "2017-12-15\n",
      "2017-12-18\n",
      "2017-12-19\n",
      "2017-12-20\n",
      "2017-12-21\n",
      "2017-12-22\n",
      "2017-12-26\n",
      "2017-12-27\n",
      "2017-12-28\n",
      "2017-12-29\n",
      "2018-01-02\n",
      "2018-01-03\n",
      "2018-01-04\n",
      "2018-01-05\n",
      "2018-01-08\n",
      "2018-01-09\n",
      "2018-01-10\n",
      "2018-01-11\n",
      "2018-01-12\n",
      "2018-01-16\n",
      "2018-01-17\n",
      "2018-01-18\n",
      "2018-01-19\n",
      "2018-01-22\n",
      "2018-01-23\n",
      "2018-01-24\n",
      "2018-01-25\n",
      "2018-01-26\n",
      "2018-01-29\n",
      "2018-01-30\n",
      "2018-01-31\n",
      "2018-02-01\n",
      "2018-02-02\n",
      "2018-02-05\n",
      "2018-02-06\n",
      "2018-02-07\n",
      "2018-02-08\n",
      "2018-02-09\n",
      "2018-02-12\n",
      "2018-02-13\n",
      "2018-02-14\n",
      "2018-02-15\n",
      "2018-02-16\n",
      "2018-02-20\n",
      "2018-02-21\n",
      "2018-02-22\n",
      "2018-02-23\n",
      "2018-02-26\n",
      "2018-02-27\n",
      "2018-02-28\n",
      "2018-03-01\n",
      "2018-03-02\n",
      "2018-03-05\n"
     ]
    }
   ],
   "source": [
    "for index, row in DIS_df.iterrows():\n",
    "    print(index)\n",
    "    DIS_df.loc[index,'SubtractDates']=subtractDates(index,'2015-01-01')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
